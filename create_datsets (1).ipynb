{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466e190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.1-cp310-cp310-win_amd64.whl (50.2 MB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\new folder\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in d:\\new folder\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: numpy in d:\\new folder\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: matplotlib in d:\\new folder\\lib\\site-packages (from mediapipe) (3.7.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\new folder\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\new folder\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (22.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\new folder\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in d:\\new folder\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in d:\\new folder\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Installing collected packages: mediapipe\n",
      "Successfully installed mediapipe-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40ab272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # imports the 'os' module, which provides a way to interact with the operating system\n",
    "import pickle #imports the 'pickle' module, which is used for serializing and deserializing Python objects\n",
    "'''imports the 'Path' class from the pathlib module. 'pathlib' provides an object-oriented approach \n",
    "to working with filesystem paths. The 'Path' class represents a filesystem 'path' and offers various \n",
    "methods for working with paths and files'''\n",
    "from pathlib import Path \n",
    "import mediapipe as mp #imports the mediapipe library, which is a popular framework for building various computer vision applications\n",
    "import cv2 #imports the 'cv2' module, which is the Python interface for 'OpenCV'\n",
    "import matplotlib.pyplot as plt #imports the 'pyplot' module from the 'matplotlib' library, which is a plotting library for Python.\n",
    "import numpy as np # imports the 'numpy' library, which is a fundamental package for scientific computing with Python\n",
    "\n",
    "'''\n",
    "These lines of code import and initialize objects and modules from the 'mediapipe' library. \n",
    "These objects and modules are used for hand tracking and drawing visualizations on images or \n",
    "videos using the 'mediapipe' framework\n",
    "'''\n",
    "mp_hands = mp.solutions.hands # creates an instance of the 'mp_hands' object using the 'mp.solutions.hands' module from the mediapipe library\n",
    "\n",
    "'''\n",
    "1. The 'Hands' class is part of the hand tracking solution provided by the 'mediapipe' library. \n",
    "By creating an instance of this class, we can use it to perform hand tracking on images or videos.\n",
    "2. 'static_image_mode=True': This parameter specifies whether the hand tracking should be optimized \n",
    "for processing static images rather than video frames.\n",
    "3. 'min_detection_confidence=0.3': This parameter sets the minimum confidence value required for a \n",
    "hand detection to be considered valid. The confidence value represents the certainty of the hand detection. \n",
    "Here, it is set to 0.3, which means that a hand detection with a confidence score below 0.3 will be discarded\n",
    "'''\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "DATA_DIR = './data4' #path to which the images are stored\n",
    "\n",
    "data = [] #intended to store the data or input samples\n",
    "labels = [] # intended to store the corresponding labels or categories associated with the data samples\n",
    "\n",
    "for dir_ in os.listdir(DATA_DIR): #iterates over each image and the values are stored in 'dir_'\n",
    "    '''\n",
    "    This line initiates a loop that iterates over the image files in the directory specified by 'os.path.join(DATA_DIR, dir_)'. \n",
    "    The 'os.path.join()' function is used to join the 'DATA_DIR' path and 'dir_' (a subdirectory or folder name) \n",
    "    to create the complete path to the directory containing the images.\n",
    "    '''\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        #These lists are used to store temporary data or variables during the processing of each image\n",
    "        data_aux = [] \n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path)) #reads the image file using 'cv2.imread()', which reads the image from the specified file path\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #used to convert the image from the default BGR color format to RGB format\n",
    "\n",
    "        '''\n",
    "        This processes the 'img_rgb' image using the hands object, which represents the hand tracking solution created earlier. \n",
    "        It detects and tracks hands in the image and stores the results in the 'results' variable\n",
    "        '''\n",
    "        results = hands.process(img_rgb)\n",
    "       \n",
    "        #This line checks if the multi_hand_landmarks attribute of the results variable is not None, indicating that at least one hand has been detected and tracked in the image\n",
    "        if not (results.multi_hand_landmarks is None): \n",
    "                n = len(results.multi_hand_landmarks) \n",
    "                '''\n",
    "                These lines check if exactly one hand is detected in the image by checking the length of the multi_hand_landmarks list. \n",
    "                If there is only one hand, the code proceeds to process the landmarks.\n",
    "                '''\n",
    "                if n == 1:\n",
    "                    try:\n",
    "                        '''\n",
    "                        These lines iterate over each hand detected and tracked in the image and extract the 'x' and 'y' coordinates of \n",
    "                        each landmark (hand keypoint) using 'hand_landmarks.landmark[i].x' and 'hand_landmarks.landmark[i].y'. \n",
    "                        The x and y coordinates are appended to the 'x_' and 'y_' lists, respectively\n",
    "                        '''\n",
    "                        for hand_landmarks in results.multi_hand_landmarks:\n",
    "                             for i in range(len(hand_landmarks.landmark)):\n",
    "                                  x= hand_landmarks.landmark[i].x\n",
    "                                  y= hand_landmarks.landmark[i].y\n",
    "                                  x_.append(x)\n",
    "                                  y_.append(y)\n",
    "                             '''\n",
    "                             These lines iterate over each landmark of the hand and calculate the relative 'x' and 'y' coordinates by subtracting \n",
    "                             the minimum x and y values from each coordinate. The relative coordinates are then appended to the 'data_aux' list\n",
    "                             '''\n",
    "                             for i in range(len(hand_landmarks.landmark)):\n",
    "                                   x = hand_landmarks.landmark[i].x\n",
    "                                   y = hand_landmarks.landmark[i].y\n",
    "                                   data_aux.append(x - min(x_))\n",
    "                                   data_aux.append(y - min(y_))\n",
    "                        data.append(data_aux) #list containing the relative coordinates for the hand landmarks is appended to the 'data' list, representing the processed data for the current image\n",
    "                        labels.append(dir_) #representing the label or category associated with the current image, is appended to the 'labels' list\n",
    "\n",
    "\n",
    "                    except:\n",
    "                            '''\n",
    "                            By assigning this zero-filled array to data_aux, it provides a default value or placeholder when an exception occurs, \n",
    "                            ensuring that data_aux has a valid value even in error scenarios\n",
    "                            '''\n",
    "                            data_aux(np.zeros([1,63], dtype=int)[0])\n",
    "\n",
    "'''\n",
    "the code opens the file \"ASL.pickle\", serializes and writes the data and labels lists as a dictionary \n",
    "to the file using the pickle.dump() function, and finally closes the file. This allows you to save the \n",
    "processed data and labels in a serialized format for later use or further analysis\n",
    "''' \n",
    "f = open('ASL2.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ebdbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
